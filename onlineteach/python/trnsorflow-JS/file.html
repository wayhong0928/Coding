<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/blazeface"></script>
    <title>File Input Detection</title>
</head>
<body>
    <div>
        選擇檔案 <input type="file" onchange="loadFile(this)" />
    </div>
    <canvas id="cvs"></canvas>
    <script>      
        const ctx=document.querySelector("#cvs").getContext("2d");
        //  載入 BlazeFace 模型  
        let model=null;
        async function init(){
            model=await blazeface.load()
        }
        init();
        function loadFile(input){
            const file=input.files[0];  //  取得使用者選擇的檔案
            console.log(file);
            //  把檔案物件變成圖片物件
            const img=new Image();
            img.src=URL.createObjectURL(file);  //  產生一個隨機的網址，對應到檔案物件
            img.addEventListener("load",()=>{
                ctx.canvas.width=img.width;
                ctx.canvas.height=img.height;
                detect(img);
            });
        }
        async function detect(img) {           
            //  利用模型對圖片做臉部辨識
            //  (圖片物件/影片物件/canvas物件,)
            const returnTensors=false;
            const predictions = await model.estimateFaces(img, returnTensors);
            if (predictions.length > 0) {   //  圖片中有臉部的存在
                //  利用迴圈把每個臉部的位置取出來
                for (let i = 0; i < predictions.length; i++) {
                    const rightEye=predictions[i].landmarks[0];
                    const leftEye=predictions[i].landmarks[1];
                    const start = predictions[i].topLeft;
                    const end = predictions[i].bottomRight;
                    const size = [end[0] - start[0], end[1] - start[1]];
                    //  把臉部的區塊清晰的畫出來
                    //  建立臉部的路徑
                    const faceArea=new Path2D();
                    faceArea.ellipse(
                        (leftEye[0]+rightEye[0])/2,(leftEye[1]+rightEye[1])/2,
                        size[0]*0.5,size[0]*0.8,
                        0,0,2*Math.PI
                    );
                    //  只把圖片畫在上面定義的路徑中
                    ctx.save();
                    ctx.clip(faceArea);
                    ctx.drawImage(img,0,0);
                    ctx.restore();
                }
            }
            //  補上模糊背景
            ctx.save();
            ctx.filter="blur(10px)";
            ctx.globalCompositeOperation="destination-atop";
            ctx.drawImage(img,0,0);
            ctx.restore();
        }
        //main();
            /*
                `predictions` is an array of objects describing each detected face, for example:

                [
                {
                    topLeft: [232.28, 145.26],
                    bottomRight: [449.75, 308.36],
                    probability: [0.998],
                    landmarks: [
                    [295.13, 177.64], // right eye
                    [382.32, 175.56], // left eye
                    [341.18, 205.03], // nose
                    [345.12, 250.61], // mouth
                    [252.76, 211.37], // right ear
                    [431.20, 204.93] // left ear
                    ]
                }
                ]
            */
    </script>
</body>
</html>